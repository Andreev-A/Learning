# При работе с файлами мы рассматриваем 2 типа файлов:
# ●	текстовые - содержимое этих файлов является текстом и может быть интерпретировано в качестве текста.
# ●	бинарные (двоичные) файлы - не являются текстом.
# Практически для любого формата бинарных файлов уже точно существуют библиотеки в языке Python, которые умеют с этим
# форматом файлом работать.
# Например:
# Библиотека для работы с графикой Pillow https://ru.wikipedia.org/wiki/Python_Imaging_Library
# Библиотека для работы со звуком wave и Python Audio Tools https://wiki.python.org/moin/Audio/
# Далее будем рассматривать преимущественно текстовые файлы.
# Основа для работы с файлами — built-in функция open()
# open(file, mode="rt")
# Эта функция имеет два аргумента. Аргумент file принимает строку, в которой содержится путь к файлу. Второй аргумент,
# mode, позволяет указать режим, в котором необходимо работать с файлом. По умолчанию этот аргумент принимает значение
# «rt», с которым, и с некоторыми другими, можно ознакомиться в таблице ниже
# Режимы открытия файлов:
# 'r' (read)	открытие на чтение (является значением по умолчанию).
# 'w' (write)	открытие на запись, содержимое файла удаляется, если файла не существует, создается новый.
# 'x'	открытие на запись, если файла не существует, иначе исключение.
# 'a' (append)	открытие на дозапись, информация добавляется в конец файла, если файла не существует, создается новый.
# 'b' (binary)	открытие в двоичном режиме.
# 't' (text)	открытие в текстовом режиме (является значением по умолчанию).
# '+'	открытие на чтение и запись
# f = open('text.txt', 'r')
# Эти режимы могут быть скомбинированы. Например, «rb» открывает двоичный файл для чтения. Комбинируя «r+» или «w+»
# можно добиться открытия файла в режиме и чтения, и записи одновременно с одним отличием — первый режим вызовет
# исключение, если файла не существует, а работа во втором режиме в таком случае создаст его.
# Функция open() возвращает нам файловый объект file object, благодаря которому мы можем читать данные, записывать
# данные. Самое главное, file object нужно закрывать, когда вы с файлом поработали. Потому что нужно освобождать те
# системные ресурсы, которые были затрачены для того, чтобы поддерживать соединение с файлом.
# С помощью метода read() мы передаем число символов, которые мы хотим считать из нашего файла.
# x = f.read(5)
# Если указать read() без параметров, то мы считаем весь файл до конца:
# y = f.read()
# Мы можем посмотреть представление считанного текста в виде одной строки с помощью функции repr()
# repr - это однозначное (недвусмысленное) представление объекта в виде строки, такой, чтобы возможно было бы из этого
# представления сделать такой же объект, в отличие от str, который служит для создания читаемого объекта
# f = open('passwords.txt', 'r', encoding='utf-8')
# x = f.read()
# print(repr(x))
# И увидим строку, включающую в себя символы переноса строки \n_test
# Для разбиения текста на отдельные строки можно использовать метод splitlines(). В результате получим строки, которые
# не содержат символов переноса строки:
# f = open('passwords.txt', 'r', encoding='utf-8')
# x = f.read()
# y = x.splitlines()
# print(y)
# Если файл занимает много места на диске, мы можем считывать его построчно с помощью метода readline().
# f = open('passwords.txt', 'r', encoding='utf-8')
# x = f.readline()
# print(repr(x))
# Символ переноса  строки останется в строке
# Для того, чтобы его убрать, можно воспользоваться методом rstrip()
# x = f.readline().rstrip()
# После того как файл считан целиком, дальнейшие попытки применить к нему метод read() будут выдавать пустую строку.
# Прочитать строку с определенным номером (например, читаем четвертую строку файла, служебные символы убираются):
# from linecache import getline
# getline('file.txt', 4)
# Для тех, кто тоже задумался о различии strip (который давали в прошлом курсе) и rstrip:
# str = "mississippim"
# print(str.strip('m'))  # убирает указанный символ в конце и в начале строки
# print(str.rstrip('m'))  # убирает указанный символ в конце строки
# print(str.lstrip('m'))  # убирает указанный символ в начале строки
# Если не указывать в скобках символ - убирают служебные символы (в т.ч. пробелы)
# В книге Лутц пишет, что можно использовать открытие файла так:
# for line in open('data.txt'):
#     print(line, end='')
# И закрывать не обязательно, так как файл открывается в инструкции цикла, как временный и закрывается автоматически
# сборщиком мусора.
# При этом он пишет, что такой вызов в данный момент является наиболее предпочтительным.
# with open('data.txt') as f:
#     for line in f:
#         print(line, end='')
# Метод lineno возвращает номер строки, которую только что прочитали.
# Перед прочтением первой строки возвращается 0. После прочтения последней строки последнего файла (если читаем
# несколько) возвращает номер строки этой строки.
# def lineno_(x):
#     return x.lineno()
# with fileinput.input(files=(file, file2)) as f:
#     for line in f:
#         print(lineno_(f))
# При записи файла нужно самостоятельно добавлять символы переноса строки:
# f = open('test.txt', 'w')
# f.write('Hello\n_test')
# f.write('world')
# f.close()
# Если у нас уже есть список строк, который нужно записать в файл, хорошей практикой будет использовать для него метод
# join() и с его помощью добавить переносы строк:
# f = open('test.txt', 'w')
# lines = ['line 1', 'line 2', 'line 3']
# contents = '\n_test'.join(lines)
# f.write(contents)
# f.close()
# Также с помощью join() мы можем склеивать не только строки, но и отдельные слова, если нам это необходимо. В этом
# случае мы можем указывать в join() символ пробел или табуляцию.
# import os
# print(repr(os.linesep))
# Для любого типа файла поможет записать корректный знак переноса.
# В языке Python важно закрывать файлы. Однако от того места, где файл открывался то того где он должен закрыться,
# могла бы произойти ошибка. В этом случае интерпретатор не дойдет до вызова метода close()
# Чтобы обезопасить себя от такой ситуации, мы можем использовать инструкцию open() вместе с конструкцией with. Когда
# выходим из блока with, интерпретатор сам закроет наш файл, независимо оттого была в блоке ошибка или нет.
# with open('test.txt') as f:
#     for line in f:
#         line = line.rstrip()
#         print(line)
# Такая конструкция гарантирует закрытие файла вне зависимости от того дошел ли интерпретатор до конца блока with или
# во время выполнения произошла ошибка. Поэтому эта конструкция является рекомендованной для работы с файлами.
# Внутри конструкции with мы можем открыть сразу несколько файлов:
# with open('test.txt') as f, open('test-copy.txt', 'w') as w:
#     for line in f:
#         w.write(line)

# import sys
# str = sys.stdin.read()
# print(str)

# from sys import stdin
# lineCount = 0
# for line in stdin:
#     lineCount += 1
# print(lineCount)

# А ещё можно без подключения библиотек вместо имени файла поставить 0 без кавычек. 0, 1 и 2 - это файловые дескрипторы,
# зарезервированные под стандартный ввод(с консоли), стандартный вывод(в консоль), вывод ошибки. То есть вместо
# output.txt можно поставить 1, и вывод пойдёт не в файл, а в консоль, как в случае с простым print().

# Библиотеки os и os.path
# С помощью функции listdir() мы можем узнать список папок и файлов.
# Запуск функции без аргументов выдает файлы и папки внутри текущей директории:
# import os
# import os.path
# print(os.listdir())
# Если в качестве аргумента указать имя определенной папки, то функция покажет ее содержимое.
# Функция os.getcwd() возвращает текущую папку:
# print(os.getcwd())
# print(os.listdir(".idea"))
# Функция exists() библиотеки os.path позволяет проверить наличие файла или папки
# print(os.path.exists("notes_dict.py"))  # True
# Мы также можем проверить является ли переданный параметр файлом или папкой с помощью функций isfile() и isdir():
# print(os.path.isfile(notes_dict.py))
# print(os.path.isdir(notes_dict.py))
# Мы можем легко узнать абсолютный путь по относительному с помощью abspath()
# print(os.path.abspath('notes_dict.py'))
# Можем сменить директорию с помощью chdir()
# os.chdir('.idea')
# print(os.getcwd())
# Функция os.walk() позволяет рекурсивно пройтись по всем папкам, подпапкам и т.д.
# Она возвращает нам генератор. И каждый раз, когда мы будем спрашивать следующее значение у этого генератора, он будет
# возвращать нам кортеж из 3 элементов:
# 1.	строковое представление текущей директории, которую он рассматривает
# 2.	список всех папок, которые есть в данной директории
# 3.	список всех файлов, которые есть в данной директории

# import os.path
#
# tree = os.walk('.')
# for current_dir, dirs, files in tree:
#     print(current_dir)
#     print(dirs)
#     print(files)
#     print('----------')
# Библиотека shutil
# Функция copy() библиотеки shutil позволяет копировать файлы.
# Она принимает 2 аргумента: откуда и куда копировать.
# import shutil
# shutil.copy('test.txt', 'tests/test3.txt')
# Функция copytree() позволяет скопировать целиком папку вместе с файлами:
# shutil.copytree('tests', 'tests/tests')

# А еще очень полезным в модуле os является возможность указания точного пути к открываемому файлу, так сказать
# "кроссплатформенно" (т.е. без путаницы в / и \ в путях):
# import os
# with open(os.path.join('C:', 'Test', 'Py', 'dataset_24465_4.txt'), 'r', encoding='utf-8') as src:
#     f = src.read()
# С помощью os.path.join система сама поставит слеш (*nix) или бек-слеш (Win), в зависимости от того - на какой ОСи
# запускается скрипт. Просто указываете имена директорий в пути.

# Очень опасные модули... os.listdir() - программа падает если передать не существующий каталог os.path.isfile и
# os.path.isdir возвращает False если их не существует, так что можно влететь os.path.abspath() - не проверяет наличие
# файла, а просто добавляет путь до текущей папки os.chdir() - падает если путь не существует shutil.copy - падает если
# исходный файл не существует и молча перезаписывает итоговый файл, если он существует В общем, при работе с модулем
# проверять каждый чих, желательно в try/except

# os.path.normpath(path) - нормализует путь, убирая избыточные разделители и ссылки на предыдущие директории. На Windows
# преобразует прямые слеши в обратные.

# С помощью os.chdir("..") можно подниматься выше по директориям, если в скобках указать путь, то перейти по этому пути
# как подняться на уровень выше в дереве каталогов? Как вариант, (обратный слеш актуален для винды):
# os.chdir('\\'.join(os.getcwd().split('\\')[:-1]))
# os.chdir(os.path.split(os.getcwd())[0])
# Начать саму работу с файлом можно с помощью объекта класса io.TextIOWrapper, который возвращается функцией open().
# У этого объекта есть несколько атрибутов, через которые можно получить информацию
# name — название файла;
# mode — режим, в котором этот файл открыт;
# closed — возвращает True, если файл был закрыт.
# По завершении работы с файлом его необходимо закрыть при помощи метода close()
# f = open("examp.le", "w")
# //  работа с файлом
# f.close()
# Однако более pythonic way стиль работы с файлом встроенными средствами заключается в использовании конструкции
# with .. as .., которая работает как менеджер создания контекста. Написанный выше пример можно переписать с ее помощью
# with open("examp.le", "w") as f:
# // работа с файлом
# Главное отличие заключается в том, что python самостоятельно закрывает файл, и разработчику нет необходимости помнить
# об этом. И бонусом к этому не будут вызваны исключения при открытии файла (например, если файл не существует).
# Чтение из файла
# При открытии файла в режимах, допускающих чтение, можно использовать несколько подходов.
# Для начала можно прочитать файл целиком и все данные, находящиеся в нем, записать в одну строку.
# with open("examp.le", "r") as f:
#     text = f.read()
# Используя эту функцию с целочисленным аргументом, можно прочитать определенное количество символов.
# with open("examp.le", "r") as f:
#     part = f.read(16)
# При этом будут получены только первые 16 символов текста. Важно понимать, что при применении этой функции несколько
# раз подряд будет считываться часть за частью этого текста — виртуальный курсор будет сдвигаться на считанную часть
# текста. Его можно сдвинуть на определенную позицию, при необходимости воспользовавшись методом seek().
# with open("examp.le", "r") as f: # 'Hello, world!'
#     first_part = f.read(8)       # 'Hello, w'
#     f.seek(4)
#     second_part = f.read(8)      # 'o, world'
# Другой способ заключается в считывании файла построчно. Метод readline() считывает строку и, также как и с методом
# read(), сдвигает курсор — только теперь уже на целую строку. Применение этого метода несколько раз будет приводить к
# считыванию нескольких строк. Схожий с этим способом, другой метод позволяет прочитать файл целиком, но по строкам,
# записав их в список. Этот список можно использовать, например, в качестве итерируемого объекта в цикле.
# with open("examp.le", "r") as f:
#     for line in f.readlines():
#         print(line)
# Однако и здесь существует более pythonic way. Он заключается в том, что сам объект io.TextIOWrapper имеет итератор,
# возвращающий строку за строкой. Благодаря этому нет необходимости считывать файл целиком, сохраняя его в список, а
# можно динамически по строкам считывать файл. И делать это лаконично.
# with open("examp.le", "r") as f:
#     for line in f:
#         print(line)
# Запись в файл
# Функциональность внесения данных в файл не зависит от режима — добавление данных или перезаписывание файла. В
# выполнении этой операции также существует несколько подходов.
# Самый простой и логичный — использование функции write()
# with open("examp.le", "w") as f:
#     f.write(some_string_data)
# Важно, что в качестве аргумента функции могут быть переданы только строки. Если необходимо записать другого рода
# информацию, то ее необходимо явно привести к строковому типу, используя методы __str__(self) для объектов или
# форматированные строки.
# Есть возможность записать в файл большой объем данных, если он может быть представлен в виде списка строк.
# with open("examp.le", "w") as f:
#     f.writelines(list_of_strings)
# Здесь есть еще один нюанс, связанный с тем, что функции write() и writelines() автоматически не ставят символ переноса
# строки, и это разработчику нужно контролировать самостоятельно.
# Существует еще один, менее известный, способ, но, возможно, самый удобный из представленных. И как бы не было странно,
# он заключается в использовании функции print(). Сначала это утверждение может показаться странным, потому что
# общеизвестно, что с помощью нее происходит вывод в консоль. И это правда. Но если передать в необязательный аргумент
# file объект типа io.TextIOWrapper, каким и является объект файла, с которым мы работаем, то поток вывода функции
# print() перенаправляется из консоли в файл.
# with open("examp.le", "w") as f:
#     print(some_data, file=f)
# Сила такого подхода заключается в том, что в print() можно передавать не обязательно строковые аргументы — при
# необходимости функция сама их преобразует к строковому типу.


# Вам дается текстовый файл, содержащий некоторое количество непустых строк.
# На основе него сгенерируйте новый текстовый файл, содержащий те же строки в обратном порядке.
# Пример входного файла:
# ab
# c
# dde
# ff
# Пример выходного файла:
# ff
# dde
# c
# ab

# with open('test.txt') as f, open('test-copy.txt', 'w') as w:
#     lst = []
#     for line in f:
#         lst.append(line.rstrip())
#     for element in reversed(lst):
#         w.write(element + '\n_test')
#
# lines = open("input.txt").readlines()
# with open("output.txt", "w") as my_input:
#     my_input.writelines(reversed(lines))
#
# with open('dataset_24465_4.txt', 'r') as fr, open('dataset_24465_4_w.txt', 'w') as fw:
#     fw.writelines(fr.readlines()[::-1])
#
# такое значение перед reverse-ом: ['ab\n_test', 'c\n_test', 'dde\n_test', 'ff'], затем reverse и печать в файл- то есть после "ff"
# нет "\n_test"; а если смотреть в документацию, то там сказано:  writelines() does not add line separators
# Прошло конечно огромное количество времени, но я все же докопался до того, что и reverse, и reversed склеят нам
# последнюю и предпоследнюю строчку. НО в нашем задании этого не случается, потому что в конечной строке также есть
# символ переноса строки.
# Сразу почуял подвох, слишком просто. Очевидно, что выгружать весь файл очень расточительно для ресурсов, немного
# поисков и нашел подходящий пакет "file_read_backwards". Код в итоге выглядит так:
#
# from file_read_backwards import FileReadBackwards
# with FileReadBackwards('file1.txt') as f, open('file2.txt','w') as w:
#     for line in f:
#         w.write(line+'\n_test')

# Вам дана в архиве (ссылка) файловая структура, состоящая из директорий и файлов.
# Вам необходимо распаковать этот архив, и затем найти в данной в файловой структуре все директории, в которых есть хотя
# бы один файл с расширением ".py".
# Ответом на данную задачу будет являться файл со списком таких директорий, отсортированных в лексикографическом порядке
# import os
# my_input = []
# for current_dir, dirs, files in os.walk('D:\\main'):
#     for file in files:
#         if file.endswith('.py'):
#             my_input.append(current_dir.lstrip('D:\\').replace('\\', '/'))
#             break
# with open('D:\\main_ans.txt', 'w') as f:
#     for element in sorted(my_input):
#         f.write(element + '\n_test')
#
# for cur_dir, subdirs, files in os.walk("main"):
#     for file in files:
#         if file.endswith(".py"):
#             print(cur_dir)
#             break
#
# result_dict = [cur_dir for cur_dir, dirs, files in os.walk("main") if any((fl.endswith(".py") for fl in files))]
# with open("py_dirs.txt", "w") as w:
#     w.write("\n_test".join(sorted(result_dict)))

# Пример обхода иерархии самого zip файла без распаковывания!!! Оригинальное задание показалась мне нелогичноым. Сами
# посудите, зачем распаковывать весь архив лишь для того чтобы узнать есть в нём необходимые файлы или нет? Логичнее
# сначала найти в архиве нужные файлы и только потом разпаковать только содержащие их папки!!! Код приведённый ниже как
# раз выполняет первую часть задачи. В модуле zipfile нету точного аналога os.walk, поэтому пришлось немного поколдовать
# чтобы не сохранять одни и те же имена папок по нескольку раз:
# import zipfile, os
# pydirs = list()
# with zipfile.ZipFile('main.zip', 'r') as zip:
#     for zip_path in zip.namelist():
#         if  os.path.dirname(zip_path) not in pydirs and os.path.basename(zip_path).endswith('.py'):
#             pydirs.append(os.path.dirname(zip_path))
# print('\n_test'.join(sorted(pydirs)))

# Мне понравилась твоя мысль, и я решил её развить далее:
# Немного сократить (и местами оптимизировать) код. Например, если ты будешь использовать `set` вместо `list`, то тебе
# не нужно будет проверять элемент на наличие в списке, и далее вообще всё свернуть в set comprehension.
# Зачем сохранять файл на диске? Он маленький, поэтому его можно вообще оставить в памяти сразу после загрузки
# Получилось вот так:
# import os, requests, zipfile, io
# url = 'https://stepik.org/media/attachments/lesson/24465/main.zip'
# with zipfile.ZipFile(io.BytesIO(requests.get(url).content)) as source:
#     pydirs = {os.path.dirname(path) for path in source.namelist() if os.path.basename(path).endswith('.py')}
# print('\n_test'.join(sorted(pydirs)))
# Поэтапно:
# Выполняем GET-запрос, получаем содержание файла
# Вешаем на полученный массив байт file-like обёртку
# Закидываем полученный объект в конструктор ZipFile
# Получаем все уникальные dirname, у которых basename заканчивается на '.py'
# Печатаем
# Это достаточное решение, потому что оно короткое, достаточно понятное (кроме строки with, её можно разбить на три
# штуки) и не зависит от порядка вывода source.namelist(). Но улучшать есть куда (с точки зрения алгоритма): во-первых,
# можно вместо set использовать bisect для поддержания сортированности и уникальности списка (однако, тогда это не
# уместилось бы в одну строку и выглядело посложнее); во-вторых, пользуясь тем, что на моей машине source.namelist()
# выдаёт список в сортированном порядке, можно просто добавлять элементы в список, сравнивая с последним добавленным,
# что делает задачу линейной по сложности. Однако далеко не факт, что это реально ускорит, поскольку чем больше мы пишем
# кода в пайтон, тем обычно он медленнее становится)

# Три года назад у меня было на три года опыта меньше в программировании и в Python в частности. А ещё степик всегда
# подстёгивает к борьбе за наименьшее количество строк, которой сложно сопротивляться. Если переписать моё решение на
# что-то более поддерживаемое, то это будет вот так:
# import os
# dirs_with_py = sorted(
#     dir_path for dir_path, _, files in os.walk("main")
#     if any(file_path.endswith(".py") for file_path in files)
# )
# for dir_path in dirs_with_py:
#     print(dir_path)
# Но с того момента уже совсем укрепилась версия Python 3.4, и это позволяет использовать pathlib
# import pathlib
# root = pathlib.Path("main")
# dirs_with_py = {path.parent for path in root.rglob("*.py")}
# for dir_path in sorted(dirs_with_py):
#     print(dir_path)
# Важное замечание. Это решение работает значительно медленнее: `rglob` наверняка медленнее чем `walk` и ещё создаётся
# дополнительный set. Но зато мы можем натурально прочитать вторую строчку: создайте множество директорий с py-файлами
# внутри.
# А теперь отвечу на вопрос )
# Часть с `any` должна быть понятной. Если непонятно, то давай пробовать приблизиться к пониманию.
# Сначала перепишем это в виде наивной функции. Вот так:
# def any_py_file(paths):
#     for path in paths:
#         if path.endswith(".py"):
#             return True
#     return False
# dirs_with_py = sorted(
#     dir_path for dir_path, _, files in os.walk("main")
#     if any_py_file(files)
# )
# Здесь мы можем увидеть вот такой паттерн:
# def any_blah_blah(iterable):
#     for item in iterable:
#         if condition(item):
#             return True
#     return False
# # Если мы видим такой паттерн, то это означает, что мы можем преобразовать iterable в последовательность значений True
# # или False — в зависимости от условия. То есть как-то так:
# def any_blah_blah(iterable):
#     boolean_iterable = (condition(item) for item in iterable)
#     for item in boolean_iterable:
#         if item:
#             return True
#     return False
# Тут я сделал круглые скобочки, а не квадратные — чтобы не инстанцировать список.
# Далее опытный глаз может заметить, что последние 4 строчки — это функция any. Перепишем!
# def any_blah_blah(iterable):
#     boolean_iterable = (condition(item) for item in iterable)
#     return any(boolean_iterable)
# Обнаружим, что можно сразу запихать туда нужный итератор.
# def any_blah_blah(iterable):
#     return any(condition(item) for item in iterable)
# Вернём наш пример
# def any_py_file(paths):
#     return any(path.endswith(".py") for path in paths)
# dirs_with_py = sorted(
#     dir_path for dir_path, _, files in os.walk("main")
#     if any_py_file(files)
# )
# Обнаружим, что смысла выделять это в отдельную функцию больше нет
# dirs_with_py = sorted(
#     dir_path for dir_path, _, files in os.walk("main")
#     if any(path.endswith(".py") for path in files)
# )
# Так как в программировании часто приходится работать с последовательностями, то эта работа часто бъётся на "кирпичики"
# из функций работы с последовательностями. Из полезных и в действительности применяемых:
# builtin-функции: all, any, enumerate, filter (редко, т.к. есть comprehension), map, max, min, next, range, reversed,
# sorted, summa, zip
# itertools
# more-itertools
# Рекомендую прокачивать понимание как работать с последовательностями без for-loop, дополнительных функций и так далее.
# Это позволит сосредоточиться на той логике, которая отличает твою программу от множества других похожих


# Hа этом занятии мы поговорим, как в Python можно считывать информацию из файлов и записывать ее в файлы. Что такое
# файлы и зачем они нужны, думаю объяснять не надо, т.к. если вы дошли до этого занятия, значит, проблем с пониманием
# таких базовых вещей у вас нет. Поэтому сразу перейдем к функции
# open(file[, mode=’r’, encoding = None, …])
# через которую и осуществляется работа с файлами. Здесь:
# - file – это путь к файлу вместе с его именем;
# - mode – режим доступа к файлу;
# - encoding – кодировка файла.
# Для начала определимся с понятием «путь к файлу». Представим, что наш файл ex1.py находится в каталоге app:
#    D:
#    |---parent
#    |     |---prt.dat
#    |--- my_input.txt
#    |---app
#         |---images
#         |     |---img.txt
#         |---exl.py
#         |---my_file.txt
# Тогда, чтобы обратиться к файлу my_file.txt путь можно записать так:
# "my_file.txt"
# или
# "d:\\app\\my_file.txt"
# или так:
# "d:/app/my_file.txt"
# Последние два варианта представляют собой абсолютный путь к файлу, то есть, полный путь, начиная с указания диска.
# Причем, обычно используют обратный слеш в качестве разделителя: так короче писать и такой путь будет корректно
# восприниматься как под ОС Windows, так и Linux. Первый же вариант – это относительный путь, относительно рабочего
# каталога.
# Теперь, предположим, мы хотим обратиться к файлу img.txt. Это можно сделать так:
# "images/img.txt"
# или так:
# "d:/app/images/img.txt"
# Для доступа к my_input.txt пути будут записаны так:
# "../my_input.txt"
# "d:/my_input.txt"
# Обратите внимание, здесь две точки означают переход к родительскому каталогу, то есть, выход из каталога app на один
# уровень вверх.
# И, наконец, для доступа к файлу prt.dat пути запишутся так:
# "../parent/prt.dat"
# "d:/ parent/prt.dat"
# Вот так следует прописывать пути к файлам. В нашем случае мы имеем текстовый файл «myfile.txt», который находится в
# том же каталоге, что и программа ex1.py, поэтому путь можно записать просто указав имя файла:
# file = open("myfile.txt")
# В результате переменная file будет ссылаться на файловый объект, через который и происходит работа с файлами. Если
# указать неверный путь, например, так:
# file = open("myfile2.txt")
# то возникнет ошибка FileNotFoundError. Это стандартное исключение и как их обрабатывать мы с вами говорили на
# предыдущем занятии. Поэтому, запишем этот критический код в блоке try:
# try:
#     file = open("myfile2.txt")
# except FileNotFoundError:
#     print("Невозможно открыть файл")
# Изменим имя файла на верное и посмотрим, как далее можно с ним работать. По умолчанию функция open открывает файл в
# текстовом режиме на чтение. Это режим
# mode = "r"
# Если нам нужно поменять режим доступа к файлу, например, открыть его на запись, то это явно указывается вторым
# параметром функции open:
# file = open("my_input.txt", "w")
# В Python имеются следующие режимы доступа:
# 'r' - открытие на чтение(значение по умолчанию)
# 'w' - открытие на запись (содержимое файла удаляется, а если его нет, то создается новый)
# 'x' - открытие файла на запись, если его нет генерирует исключение
# 'a' - открытие на дозапись (информация добавляется в конец файла)
# 'b' - открытие в бинарном режиме доступа к информации файла
# 't' - открытие в текстовом режиме доступа (если явно не указывается, то используется по умолчанию)
# '+' - открытие на чтение и запись одновременно
# Здесь мы имеем три основных режима доступа: на чтение, запись и добавление. И еще три возможных расширения этих
# режимов, например,
# 'rt' – чтение в текстовом режиме;
# 'wb' – запись в бинарном режиме;
# 'a+' – дозапись или чтение данных из файла.
# Чтение информации из файла
# В чем отличие текстового режима от бинарного мы поговорим позже, а сейчас откроем файл на чтение в текстовом режиме:
# file = open("myfile.txt")
# и прочитаем его содержимое с помощью метода read:
# print(file.read())
# В результате, получим строку, в которой будет находиться прочитанное содержимое. Действительно, в этом файле находятся
# эти строчки из поэмы Пушкина А.С. «Медный всадник». И здесь есть один тонкий момент. Наш текстовый файл имеет
# кодировку Windows-1251 и эта кодировка используется по умолчанию в функции read. Но, если изменить кодировку файла,
# например, на популярную UTF-8, то после запуска программы увидим в консоли вот такую белиберду. Как это можно
# исправить, не меняя кодировки самого файла? Для этого следует воспользоваться именованным параметром encoding и
# записать метод open вот так:
# file = open("myfile.txt", encoding="utf-8")
# Теперь все будет работать корректно. Далее, в методе read мы можем указать некий числовой аргумент, например,
# print(file.read(2))
# Тогда из файла будут считаны первые два символа. И смотрите, если мы запишем два таких вызова подряд:
# print(file.read(2))
# print(file.read(2))
# то увидим, что при следующем вызове метод read продолжил читать следующие два символа. Почему так произошло? Дело в
# том, что у файлового объекта, на который ссылается переменная file, имеется внутренний указатель позиции
# (file position), который показывает с какого места производить считывание информации. Когда мы вызываем метод read(2)
# эта позиция автоматически сдвигается от начала файла на два символа, т.к. мы именно столько считываем. И при повторном
# вызове read(2) считывание продолжается, т.е. берутся следующие два символа. Соответственно, позиция файла сдвигается
# дальше. И так, пока не дойдем до конца.#
# Но мы в Python можем управлять этой файловой позицией с помощью метода
# seek(offset[, from_what])
# Например, вот такая запись:
# file.seek(0)
# будет означать, что мы устанавливаем позицию в начало и тогда такие строчки:
# print(file.read(2))
# file.seek(0)
# print(file.read(2))
# будут считывать одни и те же первые символы. Если же мы хотим узнать текущую позицию в файле, то следует вызвать
# метод tell:
# pos = file.tell()
# print(pos)
# Следующий полезный метод – это readline позволяет построчно считывать информацию из текстового файла:
# s = file.readline()
# print(s)
# ЗЗдесь концом строки считается символ переноса ‘\n’, либо конец файла. Причем, этот символ переноса строки будет также
# присутствовать в строке. Мы в этом можем убедиться, вызвав дважды эту функцию:
# print(file.readline())
# print(file.readline())
# Здесь в консоли строчки будут разделены пустой строкой. Это как раз из-за того, что один перенос идет из прочитанной
# строки, а второй добавляется самой функцией print. Поэтому, если их записать вот так:
# print(file.readline(), end="")
# print(file.readline(), end="")
# то вывод будет построчным с одним переносом.
# Если нам нужно последовательно прочитать все строчки из файла, то для этого обычно используют цикл for следующим
# образом:
#     for line in file:
#         print(line, end="")
# Этот пример показывает, что объект файл является итерируемым и на каждой итерации возвращает очередную строку.
# Или же, все строчки можно прочитать методом
# s = file.readlines()
# и тогда переменная s будет ссылаться на упорядоченный список с этими строками:
# print(s)
# Однако этот метод следует использовать с осторожностью, т.к. для больших файлов может возникнуть ошибка нехватки
# памяти для хранения полученного списка.
# По сути это все методы для считывания информации из файла. И, смотрите, как только мы завершили работу с файлом, его
# следует закрыть. Для этого используется метод close:
# file.close()
# Конечно, прописывая эту строчку, мы не увидим никакой разницы в работе программы. Но, во-первых, закрывая файл, мы
# освобождаем память, связанную с этим файлом и, во-вторых, у нас не будет проблем в потере данных при их записи в файл.
# А, вообще, лучше просто запомнить: после завершения работы с файлом, его нужно закрыть. Причем, организовать программу
# лучше так:
# try:
#     file = open("myfile.txt")
#     try:
#         s = file.readlines()
#         print(s)
#     finally:
#         file.close()
# except FileNotFoundError:
#     print("Невозможно открыть файл")
# Мы здесь создаем вложенный блок try, в который помещаем критический текст программы при работе с файлом и далее блок
# finally, который будет выполнен при любом стечении обстоятельств, а значит, файл гарантированно будет закрыт.
# Или же, забегая немного вперед, отмечу, что часто для открытия файла пользуются так называемым менеджером контекста,
# когда файл открывают при помощи оператора with:
# try:
#     with open("myfile.txt", "r") as file:  # file = open("myfile.txt")
#         s = file.readlines()
#         print(s)
# except FileNotFoundError:
#     print("Невозможно открыть файл")
# При таком подходе файл закрывается автоматически после выполнения всех инструкций внутри этого менеджера. В этом можно
# убедиться, выведем в консоль флаг, сигнализирующий закрытие файла:
# finally:
# print(file.closed)
# Запустим программу, видите, все работает также и при этом файл автоматически закрывается. Даже если произойдет
# критическая ошибка, например, пропишем такую конструкцию:
# print(int(s))
# то, как видим, файл все равно закрывается. Вот в этом удобство такого подхода при работе с файлами.
# Запись информации в файл
# Теперь давайте посмотрим, как происходит запись информации в файл. Во-первых, нам нужно открыть файл на запись,
# например, так:
# file = open("my_input.txt", "w")
# и далее вызвать метод write:
# file.write("Hello World!")
# В результате у нас будет создан файл my_input.txt со строкой «Hello World!». Причем, этот файл будет располагаться в том же
# каталоге, что и файл с текстом программы на Python.
# Далее сделаем такую операцию: запишем метод write следующим образом:
# file.write("Hello")
# И снова выполним эту программу. Смотрите, в нашем файле my_input.txt прежнее содержимое исчезло и появилось новое – строка
# «Hello». То есть, когда мы открываем файл на запись в режимах w, wt, wb, топрежнее содержимое файла удаляется. Вот
# этот момент следует всегда помнить.#
# Теперь посмотрим, что будет, если вызвать метод write несколько раз подряд:
# file.write("Hello1")
# file.write("Hello2")
# file.write("Hello3")
# Смотрите, у нас в файле появились эти строчки друг за другом. То есть, здесь как и со считыванием: объект file
# записывает информацию, начиная с текущей файловой позиции, и автоматически перемещает ее при выполнении метода write.
# Если мы хотим записать эти строчки в файл каждую с новой строки, то в конце каждой пропишем символ переноса строки:
# file.write("Hello1\n")
# file.write("Hello2\n")
# file.write("Hello3\n")
# Далее, для дозаписи информации в файл, то есть, записи с сохранением предыдущего содержимого, файл следует открыть в
# режиме ‘a’:
# file = open("my_input.txt", "a")
# ТТогда, выполняя эту программу, мы в файле увидим уже шесть строчек. И смотрите, в зависимости от режима доступа к
# файлу, мы должны использовать или методы для записи, или методы для чтения. Например, если вот здесь попытаться
# прочитать информацию с помощью метода read:
# file.read()
# то возникнет ошибка доступа. Если же мы хотим и записывать и считывать информацию, то можно воспользоваться режимом a+
# file = open("my_input.txt", "a+")
# Так как здесь файловый указатель стоит на последней позиции, то для считывания информации, поставим его в самое начало
# file.seek(0)
# print(file.read())
# А вот запись данных всегда осуществляется в конец файла.
# Следующий полезный метод для записи информации – это writelines:
# file.writelines(["Hello1\n", "Hello2\n"])
# Он записывает несколько строк, указанных в коллекции. Иногда это бывает удобно, если в процессе обработки текста мы
# имеем список и его требуется целиком поместить в файл.
# Чтение и запись в бинарном режиме доступа
# Что такое бинарный режим доступа? Это когда данные из файла считываются один в один без какой-либо обработки. Обычно
# это используется для сохранения и считывания объектов. Давайте предположим, что нужно сохранить в файл вот такой
# список:
# books = [
#     ("Евгений Онегин", "Пушкин А.С.", 200),
#     ("Муму", "Тургенев И.С.", 250),
#     ("Мастер и Маргарита", "Булгаков М.А.", 500),
#     ("Мертвые души", "Гоголь Н.В.", 190)
# ]
# Откроем файл на запись в бинарном режиме:
# file = open("my_input.bin", "wb")
# Далее, для работы с бинарными данными подключим специальный встроенный модуль pickle:
# import pickle
# И вызовем него метод dump:
# pickle.dump(books, file)
# Все, мы сохранили этот объект в файл. Теперь прочитаем эти данные. Откроем файл на чтение в бинарном режиме:
# file = open("my_input.bin", "rb")
# и далее вызовем метод load модуля pickle:
# bs = pickle.load(file)
# Все, теперь переменная bs ссылается на эквивалентный список:
# print(bs)
# Аналогичным образом можно записывать и считывать сразу несколько объектов. Например, так:
# import pickle
# book1 = ["Евгений Онегин", "Пушкин А.С.", 200]
# book2 = ["Муму", "Тургенев И.С.", 250]
# book3 = ["Мастер и Маргарита", "Булгаков М.А.", 500]
# book4 = ["Мертвые души", "Гоголь Н.В.", 190]
# try:
#     file = open("my_input.bin", "wb")
#     try:
#         pickle.dump(book1, file)
#         pickle.dump(book2, file)
#         pickle.dump(book3, file)
#         pickle.dump(book4, file)
#     finally:
#         file.close()
# except FileNotFoundError:
#     print("Невозможно открыть файл")
# А, затем, считывание в том же порядке:
# file = open("my_input.bin", "rb")
# b1 = pickle.load(file)
# b2 = pickle.load(file)
# b3 = pickle.load(file)
# b4 = pickle.load(file)
# print(b1, b2, b3, b4, sep="\n")
# Вот так в Python выполняется запись и считывание данных из файла.


